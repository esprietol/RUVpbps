---
title: "ruvPBPS"
output: rmarkdown::html_vignette
vignette: >
  %\VignetteIndexEntry{ruvPBPS}
  %\VignetteEngine{knitr::rmarkdown}
  %\VignetteEncoding{UTF-8}
---

```{r, include = FALSE,message=FALSE,warning=FALSE}
knitr::opts_chunk$set(
  collapse = TRUE,
  comment = "#>"
)
```

```{r setup}

library(RUVpbps)
library(tidyr)
library(dplyr)
library(edgeR)

```

# Overview

External factors, for instance reagent batches, often introduce technical noise in high-dimensional biological data and can lead to erroneous biological conclusions. RUV (Remove Unwanted Variation) methods estimate and correct for unknown, unwanted technical noise;  they are particularly used in the context of gene expression analysis. RUV methods estimate a set of latent variables (unwanted factors) that are associated with the systematic technical noise. To estimate the unwanted factors, RUV methods rely in sets of negative control samples (replicates with low biological variation) and/or negative control genes (genes with constant expression across samples). In the absence of (sufficient) technical replicates and plausible negative control genes, factors of unwanted variation can not be estimated. In the pseudobulk context, we tackled this problem by introducing pseudobulk pseudosamples (PBPS), which are artificial samples generated by pseudobulking cells with similar characteristics, accounting for biological and known technical variables.

Let $\mathcal{C}$ represent the set of all cells in the dataset. The PBPS are created as follows:

1. Identify the biological covariates, i.e., the covariates that are associated with variation we are interested in (e.g., the cell type). We will denote each level of (the combination of) such covariate(s) by $b \in \{1, \ldots, B\}$. Similarly, identify the known sources of unwanted variation, i.e., the covariates associated with the batch effects (e.g., the batch identifiers), and denote the levels by $l \in \{1, \ldots, L\}$. 
    
2. Group cells from single-cell samples that share the same values for the biological covariates. Each group will be called a biological subgroup $b$. These sets are denoted as $\mathcal{C}_b$.
    
3. Within each biological subgroup $b$, compute the average number of cells in single-cell samples, denoted as $\bar{c}_b$.

4. Within each biological subgroup $b$, group cells that share the same value for the known sources of unwanted variation. Denote this set as $\mathcal{C}_{bl}$.

5. Draw $I$ random samples (cells) with replacement of size $\bar{c}_b$ from every set $\mathcal{C}_{bl}$. 

6. Pseudobulk the cells from every random sample $i$, with $i=1,...,I$, to obtain the pseudobulk pseudosample $s'_{bli}$.

At the end, we create a new count matrix $\mb{Y'}_p$ of size $(S + S')\times G$ containing pseudobulk counts from the $S$ original samples and the $S'$ new pseudosamples; note that the number of pseudosamples $S'$ is determined by the number of random samples $I$ and the number of $\mathcal{C}_{bl}$ sets. 

The process is summarised in the `gen_PBPS` function.

# Workflow

To use the `gen_PBPS` function, we required a `SeuratObject` with annotated cells from multiple samples and a meta.data slot with biological and technical covariates.
In this case, we use the `dummysc` dataset included in this package to demostrate the process. Among other variables, the metadata of the file has a sample identifier: `ind_cov_batch_cov`, a subject identifier `ind_cov`, a technical variable `Processing_Cohort`, and a biological variable, that happens to be the cell annotation (or cell type) `cg_cov`.

The samples are distributed in two processing cohorts. Two samples were taken from the same subject: 'IGTB195_IGTB195'. There are two cell types in the dataset, T4 and T8, and all samples have at least 394 cells from each cell type.


```{r}

data(dummysc)

samples_info <- dummysc@meta.data[,c("ind_cov","ind_cov_batch_cov","cg_cov","sample_cell","Processing_Cohort")]

group_by(samples_info, ind_cov_batch_cov, ind_cov, Processing_Cohort, cg_cov) |> summarise(n=n(),.groups = "drop") |>pivot_wider(names_from=cg_cov,values_from=n)



```



We start by pseudobulking the single cell data based on the sample/cell type identifier `sample_cell`, we use DGEList objects to store the pseudobulk data.

```{r}

PBC <- Seurat::AggregateExpression(dummysc, group.by = "sample_cell", return.seurat = FALSE)

  # Identify sample-level covariates
  unique_pb <- dummysc@meta.data |>
    dplyr::group_by(sample_cell) |>
    dplyr::summarise(dplyr::across(dplyr::everything(), dplyr::n_distinct), .groups = "drop") |>
    dplyr::select(-sample_cell) |>
    colSums()

  metacovs <- c("sample_cell", names(unique_pb)[unique_pb == dplyr::n_distinct(dummysc@meta.data[["sample_cell"]])])

  # Create DGEList
  PBC <- edgeR::DGEList(counts = PBC[[1]], samples = unique(dummysc@meta.data[, metacovs]))
  

```


Then we filter and normalise the pseudobulk counts, and visualise the data.

```{r}

PBC_T4 <- PBC[rowSums(PBC$counts>=10)>=5,PBC$samples$cg_cov=="T4"]

PBC_T4 <- calcNormFactors(PBC_T4,method="upperquartile")


```

